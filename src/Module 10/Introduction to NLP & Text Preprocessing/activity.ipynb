{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title : NLP Applications\n",
    "\n",
    "# 1. Chatbots\n",
    "# Task 1: Explore a simple chatbot using a rule-based approach to answer greetings.\n",
    "# Task 2: Analyze a chatbot's response to frequently asked questions in customer service.\n",
    "# Task 3: Build a simple chatbot using a conversational AI platform like Dialogflow or Rasa.\n",
    "\n",
    "# 2. Sentiment Analysis\n",
    "# Task 1: Use a pre-trained model to determine the sentiment (positive/negative) of a tweet.\n",
    "# Task 2: Analyze customer reviews to classify them as positive or negative.\n",
    "# Task 3: Create a simple Python script using a library like TextBlob to analyze sentiment in a text.\n",
    "\n",
    "# 3. Machine Translation\n",
    "# Task 1: Translate a simple text from English to Spanish using Google Translate API.\n",
    "# Task 2: Use a pre-trained model like OpenNMT to translate sentences from French to English.\n",
    "# Task 3: Explore language translation features in cloud-based NLP services like AWS Translate.\n",
    "\n",
    "# Title : Basic Text Preprocessing\n",
    "\n",
    "# 1. Tokenization (Word & Sentence Tokenization)\n",
    "# Task 1: Tokenize a sentence into words using NLTK in Python.\n",
    "# Task 2: Split a paragraph into sentences using spaCy.\n",
    "# Task 3: Example 3: Use the Hugging Face tokenizer to tokenize sentences from a document.\n",
    "\n",
    "# 2. Stopword Removal\n",
    "# Task 1: Identify and remove stopwords from a sentence using NLTK.\n",
    "# Task 2: Use spaCy to exclude stopwords from processing a list of words.\n",
    "# Task 3: Create a custom list of stopwords and remove them from a text.\n",
    "\n",
    "# 3. Lemmatization vs. Stemming\n",
    "# Task 1: Apply stemming using the Porter Stemmer in NLTK and observe the results.\n",
    "# Task 2: Use spaCy's lemmatizer to process and compare words with their base form.\n",
    "# Task 3: Compare the output of stemming and lemmatization for a list of words.\n",
    "    \n",
    "# 4. Punctuation & Special Character Removal\n",
    "# Task 1: Write a Python function to remove punctuation from a string.\n",
    "# Task 2: Use regular expressions (regex) to clean a text by removing special characters.\n",
    "# Task 3: Apply a text cleaner library, such as clean-text , to remove both punctuation and special characters.\n",
    "\n",
    "# Title : Text Representation Techniques\n",
    "\n",
    "# 1. Bag of Words (BoW)\n",
    "# Task 1: Create a Bag of Words model from a simple corpus using Python's CountVectorizer .\n",
    "# Task 2: Visualize the word frequencies in a document by generating a Bag of Words.\n",
    "# Task 3: Use the BoW model to compare textual similarity between two short documents.\n",
    "\n",
    "# 2. Term Frequency-Inverse Document Frequency (TF-IDF)\n",
    "# Task 1: Generate TF-IDF values for a small dataset using TfidfVectorizer in Python.\n",
    "# Task 2: Compare the importance of various terms in a corpus using their TF-IDF scores.\n",
    "# Task 3: Use the TF-IDF representation to perform a similarity search on a text dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
