{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title : Part 2: Deep Learning Architectures for NLP\n",
    "\n",
    "# 3. Transformer Models (BERT, GPT):\n",
    "\n",
    "# Task 1: Explore the architecture of a transformer model by implementing a simplified version using TensorFlow or PyTorch .\n",
    "# Task 2: Fine-tune a pre-trained BERT model for a named entity recognition (NER) task.\n",
    "# Task 3: Utilize GPT for generating language output based on a given prompt.\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
